{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scorecardpy as sc\n",
    "import pprint\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114755 entries, 0 to 114754\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Unnamed: 0                114755 non-null  int64  \n",
      " 1   STATUS                    114755 non-null  int64  \n",
      " 2   NAME_CONTRACT_TYPE        114755 non-null  object \n",
      " 3   FLAG_OWN_CAR              114755 non-null  object \n",
      " 4   FLAG_OWN_REALTY           114755 non-null  object \n",
      " 5   AMT_INCOME_TOTAL          114755 non-null  float64\n",
      " 6   AMT_CREDIT                114755 non-null  float64\n",
      " 7   AMT_ANNUITY               114755 non-null  float64\n",
      " 8   NAME_INCOME_TYPE          114755 non-null  object \n",
      " 9   NAME_EDUCATION_TYPE       114755 non-null  object \n",
      " 10  NAME_FAMILY_STATUS        114755 non-null  object \n",
      " 11  NAME_HOUSING_TYPE         114755 non-null  object \n",
      " 12  DAYS_EMPLOYED             114755 non-null  int64  \n",
      " 13  OCCUPATION_TYPE           114755 non-null  object \n",
      " 14  CNT_FAM_MEMBERS           114755 non-null  float64\n",
      " 15  EXT_SOURCE_2              114564 non-null  float64\n",
      " 16  DEF_60_CNT_SOCIAL_CIRCLE  114755 non-null  float64\n",
      " 17  age                       114755 non-null  float64\n",
      " 18  total_enquiries_cb        114755 non-null  float64\n",
      " 19  credit_income_ratio       114755 non-null  float64\n",
      "dtypes: float64(9), int64(3), object(8)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_csv('filtered_data_iter2.csv')\n",
    "df = df_main.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    104221\n",
       "1     10534\n",
       "Name: STATUS, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace value 0 in status with 2\n",
    "# df[\"STATUS\"].replace(0,2,inplace=True)\n",
    "# df[\"STATUS\"].replace(1,0,inplace=True)\n",
    "# df[\"STATUS\"].replace(2,1,inplace=True)\n",
    "df[\"STATUS\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  0\n",
       "STATUS                      0\n",
       "NAME_CONTRACT_TYPE          0\n",
       "FLAG_OWN_CAR                0\n",
       "FLAG_OWN_REALTY             0\n",
       "AMT_INCOME_TOTAL            0\n",
       "AMT_CREDIT                  0\n",
       "AMT_ANNUITY                 0\n",
       "NAME_INCOME_TYPE            0\n",
       "NAME_EDUCATION_TYPE         0\n",
       "NAME_FAMILY_STATUS          0\n",
       "NAME_HOUSING_TYPE           0\n",
       "DAYS_EMPLOYED               0\n",
       "OCCUPATION_TYPE             0\n",
       "CNT_FAM_MEMBERS             0\n",
       "EXT_SOURCE_2                0\n",
       "DEF_60_CNT_SOCIAL_CIRCLE    0\n",
       "age                         0\n",
       "total_enquiries_cb          0\n",
       "credit_income_ratio         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for col in df.columns:\n",
    "    data_dict[col] = [str(df[col].dtypes)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME_CONTRACT_TYPE {'Cash loans': 0, 'Revolving loans': 1}\n",
      "FLAG_OWN_CAR {'N': 0, 'Y': 1}\n",
      "FLAG_OWN_REALTY {'N': 0, 'Y': 1}\n",
      "NAME_INCOME_TYPE {'Businessman': 0, 'Commercial associate': 1, 'Pensioner': 2, 'State servant': 3, 'Student': 4, 'Working': 5}\n",
      "NAME_EDUCATION_TYPE {'Academic degree': 0, 'Higher education': 1, 'Incomplete higher': 2, 'Lower secondary': 3, 'Secondary / secondary special': 4}\n",
      "NAME_FAMILY_STATUS {'Civil marriage': 0, 'Married': 1, 'Separated': 2, 'Single / not married': 3, 'Widow': 4}\n",
      "NAME_HOUSING_TYPE {'Co-op apartment': 0, 'House / apartment': 1, 'Municipal apartment': 2, 'Office apartment': 3, 'Rented apartment': 4, 'With parents': 5}\n",
      "OCCUPATION_TYPE {'Accountants': 0, 'Cleaning staff': 1, 'Cooking staff': 2, 'Core staff': 3, 'Drivers': 4, 'HR staff': 5, 'High skill tech staff': 6, 'IT staff': 7, 'Laborers': 8, 'Low-skill Laborers': 9, 'Managers': 10, 'Medicine staff': 11, 'Not Specified': 12, 'Private service staff': 13, 'Realty agents': 14, 'Sales staff': 15, 'Secretaries': 16, 'Security staff': 17, 'Waiters/barmen staff': 18}\n",
      "STATUS {0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "# define the target variable\n",
    "target = df['STATUS']\n",
    "\n",
    "# create a list of object columns\n",
    "object_list = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "# create a dictionary to store the original categorical variables and their encoded values\n",
    "cat_dict = {}\n",
    "\n",
    "df_label_encoded = df.copy()\n",
    "# label encode all object columns and store the original categorical variables and their encoded values\n",
    "for col in object_list:\n",
    "    le = LabelEncoder()\n",
    "    df_label_encoded[col] = le.fit_transform(df[col])\n",
    "    cat_dict[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# label encode the target variable and add it to the dictionary\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(target)\n",
    "cat_dict['STATUS'] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# print the dictionary\n",
    "for (k,v) in cat_dict.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After label encoding, certain categories such as OCCUPATION_TYPE have an arbitrary and misleading order. The order of the encoded categories may not reflect the actual relationship between the categories. In the label encoded order above, **Accountants** have a low encoding label and would be likely binned with **Cleaning** and **Cooking staff** despite a much lower default rate as seen in the data below. This could potentially lead to inaccurate binning and scorecard creation, which could produce irrational scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCCUPATION_TYPE\n",
       "Low-skill Laborers       0.180932\n",
       "Cooking staff            0.125254\n",
       "Cleaning staff           0.124682\n",
       "Security staff           0.121001\n",
       "Waiters/barmen staff     0.114334\n",
       "Laborers                 0.113637\n",
       "Drivers                  0.112117\n",
       "Sales staff              0.103980\n",
       "Realty agents            0.099502\n",
       "Not Specified            0.084891\n",
       "Secretaries              0.081413\n",
       "Medicine staff           0.079542\n",
       "Managers                 0.067038\n",
       "High skill tech staff    0.066873\n",
       "HR staff                 0.064516\n",
       "Core staff               0.063942\n",
       "Private service staff    0.063846\n",
       "Accountants              0.051250\n",
       "IT staff                 0.048387\n",
       "Name: STATUS, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df['OCCUPATION_TYPE'])['STATUS'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will group occupation types into 5 categories based on the corresponding default rates for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].map({'Low-skill Labourers': 0, 'Cooking staff': 1, 'Cleaning staff': 2, 'Security staff': 3, 'Waiters/barmen staff': 4})\n",
    "df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].map({'Labourers': 5, 'Drivers': 6, 'Sales staff': 7, 'Realty agents': 8, 'Secretaries': 9})\n",
    "df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].map({'Not Specified': 10})\n",
    "df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].map({'Medicine staff': 11, 'Managers': 12, 'High skill tech staff': 13, 'HR staff ': 14})\n",
    "df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].map({'Core staff': 15, 'Private service staff': 16, 'Accountants': 17, 'IT staff': 18})\n",
    "cat_dict['OCCUPATION_TYPE'] = {'Low-skill Labourers': 0, 'Cooking staff': 1, 'Cleaning staff': 2, 'Security staff': 3, 'Waiters/barmen staff': 4, 'Labourers': 5, 'Drivers': 6, 'Sales staff': 7, 'Realty agents': 8, 'Secretaries': 9, 'Not Specified': 10, 'Medicine staff': 11, 'Managers': 12, 'High skill tech staff': 13, 'HR staff ': 14, 'Core staff': 15, 'Private service staff': 16, 'Accountants': 17, 'IT staff': 18}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mitigate this issue, we will perform manual label encoding for categories that can be easily ordered without biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education labels are in order of increasing education level\n",
    "df['NAME_EDUCATION_TYPE'] = df['NAME_EDUCATION_TYPE'].map({'Lower secondary': 0, 'Secondary/ secondary special': 1, 'Incomplete higher': 2, 'Higher education': 3, 'Academic degree': 4})\n",
    "cat_dict['NAME_EDUCATION_TYPE'] = {'Lower secondary': 0, 'Secondary/ secondary special': 1, 'Incomplete higher': 2, 'Higher education': 3, 'Academic degree': 4}\n",
    "\n",
    "# Income labels are in order of increasing income level\n",
    "df['NAME_INCOME_TYPE'] = df['NAME_INCOME_TYPE'].map({'Student': 0, 'Pensioner': 1, 'Working': 2, 'State servant': 3, 'Commercial associate': 4, 'Businessman': 5})\n",
    "cat_dict['NAME_INCOME_TYPE'] = {'Student': 0, 'Pensioner': 1, 'Working': 2, 'State servant': 3, 'Commercial associate': 4, 'Businessman': 5}\n",
    "\n",
    "# Housing labels are in order of increasing loan burden on the individual\n",
    "df['NAME_HOUSING_TYPE'] = df['NAME_HOUSING_TYPE'].map({'With parents': 0, 'Rented apartment': 1, 'Municipal apartment': 2, 'Office apartment': 3, 'Co-op apartment': 4, 'House / apartment': 5})\n",
    "cat_dict['NAME_HOUSING_TYPE'] = {'With parents': 0, 'Rented apartment': 1, 'Municipal apartment': 2, 'Office apartment': 3, 'Co-op apartment': 4, 'House / apartment': 5}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining variables, perform label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_encodings = ['OCCUPATION_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_INCOME_TYPE', 'NAME_HOUSING_TYPE']\n",
    "\n",
    "# define the target variable\n",
    "target = df['STATUS']\n",
    "\n",
    "# create a list of object columns\n",
    "object_list = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "# create a dictionary to store the original categorical variables and their encoded values\n",
    "df_label_encoded = df.copy()\n",
    "# label encode all object columns and store the original categorical variables and their encoded values\n",
    "for col in set(object_list) - set(manual_encodings):\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    cat_dict[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# label encode the target variable and add it to the dictionary\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(target)\n",
    "cat_dict['STATUS'] = dict(zip(le.classes_, le.transform(le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME_CONTRACT_TYPE {'Cash loans': 0, 'Revolving loans': 1}\n",
      "FLAG_OWN_CAR {'N': 0, 'Y': 1}\n",
      "FLAG_OWN_REALTY {'N': 0, 'Y': 1}\n",
      "NAME_INCOME_TYPE {'Student': 0, 'Pensioner': 1, 'Working': 2, 'State servant': 3, 'Commercial associate': 4, 'Businessman': 5}\n",
      "NAME_EDUCATION_TYPE {'Lower secondary': 0, 'Secondary/ secondary special': 1, 'Incomplete higher': 2, 'Higher education': 3, 'Academic degree': 4}\n",
      "NAME_FAMILY_STATUS {'Civil marriage': 0, 'Married': 1, 'Separated': 2, 'Single / not married': 3, 'Widow': 4}\n",
      "NAME_HOUSING_TYPE {'With parents': 0, 'Rented apartment': 1, 'Municipal apartment': 2, 'Office apartment': 3, 'Co-op apartment': 4, 'House / apartment': 5}\n",
      "OCCUPATION_TYPE {'Low-skill Labourers': 0, 'Cooking staff': 1, 'Cleaning staff': 2, 'Security staff': 3, 'Waiters/barmen staff': 4, 'Labourers': 5, 'Drivers': 6, 'Sales staff': 7, 'Realty agents': 8, 'Secretaries': 9, 'Not Specified': 10, 'Medicine staff': 11, 'Managers': 12, 'High skill tech staff': 13, 'HR staff ': 14, 'Core staff': 15, 'Private service staff': 16, 'Accountants': 17, 'IT staff': 18}\n",
      "STATUS {0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "# print the dictionary\n",
    "for (k,v) in cat_dict.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>age</th>\n",
       "      <th>total_enquiries_cb</th>\n",
       "      <th>credit_income_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>1560726.0</td>\n",
       "      <td>41301.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "      <td>-3130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.127053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>652500.0</td>\n",
       "      <td>21177.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "      <td>-679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.651862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>80865.0</td>\n",
       "      <td>5881.5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "      <td>-2717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.715042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>918468.0</td>\n",
       "      <td>28966.5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "      <td>-3028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.566907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.082080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>509602.5</td>\n",
       "      <td>26149.5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "      <td>-1317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.236378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.718542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  STATUS  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0           0       0                   0             1                1   \n",
       "1           2       0                   0             0                1   \n",
       "2           3       0                   0             0                1   \n",
       "3           4       0                   0             1                0   \n",
       "4           6       0                   0             0                0   \n",
       "\n",
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  NAME_INCOME_TYPE  \\\n",
       "0          171000.0   1560726.0      41301.0                 4   \n",
       "1          112500.0    652500.0      21177.0                 2   \n",
       "2           67500.0     80865.0       5881.5                 2   \n",
       "3          225000.0    918468.0      28966.5                 2   \n",
       "4          108000.0    509602.5      26149.5                 2   \n",
       "\n",
       "   NAME_EDUCATION_TYPE NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_EMPLOYED  \\\n",
       "0                  3.0            Married                  5          -3130   \n",
       "1                  3.0            Married                  5           -679   \n",
       "2                  NaN            Married                  5          -2717   \n",
       "3                  NaN            Married                  5          -3028   \n",
       "4                  NaN            Married                  5          -1317   \n",
       "\n",
       "   OCCUPATION_TYPE  CNT_FAM_MEMBERS  EXT_SOURCE_2  DEF_60_CNT_SOCIAL_CIRCLE  \\\n",
       "0              NaN              3.0      0.724000                       0.0   \n",
       "1              NaN              3.0      0.651862                       0.0   \n",
       "2              NaN              2.0      0.715042                       0.0   \n",
       "3              NaN              3.0      0.566907                       0.0   \n",
       "4              NaN              2.0      0.236378                       0.0   \n",
       "\n",
       "    age  total_enquiries_cb  credit_income_ratio  \n",
       "0  37.0                 4.0             9.127053  \n",
       "1  27.0                 1.0             5.800000  \n",
       "2  36.0                 1.0             1.198000  \n",
       "3  38.0                 1.0             4.082080  \n",
       "4  35.0                 1.0             4.718542  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Can only pass argument \"on\" OR \"left_index\" and \"right_index\", not a combination of both.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Shuoan\\Desktop\\Financial Analytics\\FA\\Part 3.1c - Coarse Classing and creating Scorecard with manual encoding.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shuoan/Desktop/Financial%20Analytics/FA/Part%203.1c%20-%20Coarse%20Classing%20and%20creating%20Scorecard%20with%20manual%20encoding.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# automatically calculate bin ranges\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shuoan/Desktop/Financial%20Analytics/FA/Part%203.1c%20-%20Coarse%20Classing%20and%20creating%20Scorecard%20with%20manual%20encoding.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# bins = sc.woebin(df, y='STATUS',positive=\"bad|0\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Shuoan/Desktop/Financial%20Analytics/FA/Part%203.1c%20-%20Coarse%20Classing%20and%20creating%20Scorecard%20with%20manual%20encoding.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m bins \u001b[39m=\u001b[39m sc\u001b[39m.\u001b[39;49mwoebin(df, y\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSTATUS\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shuoan/Desktop/Financial%20Analytics/FA/Part%203.1c%20-%20Coarse%20Classing%20and%20creating%20Scorecard%20with%20manual%20encoding.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# make it easy to read the bins\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shuoan/Desktop/Financial%20Analytics/FA/Part%203.1c%20-%20Coarse%20Classing%20and%20creating%20Scorecard%20with%20manual%20encoding.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m variables , bindetails \u001b[39min\u001b[39;00m bins\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\Shuoan\\anaconda3\\lib\\site-packages\\scorecardpy\\woebin.py:958\u001b[0m, in \u001b[0;36mwoebin\u001b[1;34m(dt, y, x, var_skip, breaks_list, special_values, stop_limit, count_distr_limit, bin_num_limit, positive, no_cores, print_step, method, ignore_const_cols, ignore_datetime_cols, check_cate_num, replace_blank, save_breaks_list, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m             \u001b[39mprint\u001b[39m((\u001b[39m'\u001b[39m\u001b[39m{\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mstr\u001b[39m(xs_len)))\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.0f}/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mformat(i, xs_len, x_i), flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    957\u001b[0m         \u001b[39m# woebining on one variable\u001b[39;00m\n\u001b[1;32m--> 958\u001b[0m         bins[x_i] \u001b[39m=\u001b[39m woebin2(\n\u001b[0;32m    959\u001b[0m           dtm \u001b[39m=\u001b[39;49m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m:dt[y], \u001b[39m'\u001b[39;49m\u001b[39mvariable\u001b[39;49m\u001b[39m'\u001b[39;49m:x_i, \u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m:dt[x_i]}),\n\u001b[0;32m    960\u001b[0m           breaks\u001b[39m=\u001b[39;49mbreaks_list[x_i] \u001b[39mif\u001b[39;49;00m (breaks_list \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m) \u001b[39mand\u001b[39;49;00m (x_i \u001b[39min\u001b[39;49;00m breaks_list\u001b[39m.\u001b[39;49mkeys()) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    961\u001b[0m           spl_val\u001b[39m=\u001b[39;49mspecial_values[x_i] \u001b[39mif\u001b[39;49;00m (special_values \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m) \u001b[39mand\u001b[39;49;00m (x_i \u001b[39min\u001b[39;49;00m special_values\u001b[39m.\u001b[39;49mkeys()) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    962\u001b[0m           init_count_distr\u001b[39m=\u001b[39;49minit_count_distr,\n\u001b[0;32m    963\u001b[0m           count_distr_limit\u001b[39m=\u001b[39;49mcount_distr_limit,\n\u001b[0;32m    964\u001b[0m           stop_limit\u001b[39m=\u001b[39;49mstop_limit, \n\u001b[0;32m    965\u001b[0m           bin_num_limit\u001b[39m=\u001b[39;49mbin_num_limit,\n\u001b[0;32m    966\u001b[0m           method\u001b[39m=\u001b[39;49mmethod\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m         \u001b[39m# try catch:\u001b[39;00m\n\u001b[0;32m    969\u001b[0m         \u001b[39m# \"The variable '{}' caused the error: '{}'\".format(x_i, error-info)\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    971\u001b[0m     pool \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mPool(processes\u001b[39m=\u001b[39mno_cores)\n",
      "File \u001b[1;32mc:\\Users\\Shuoan\\anaconda3\\lib\\site-packages\\scorecardpy\\woebin.py:722\u001b[0m, in \u001b[0;36mwoebin2\u001b[1;34m(dtm, breaks, spl_val, init_count_distr, count_distr_limit, stop_limit, bin_num_limit, method)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtree\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    721\u001b[0m         \u001b[39m# 2.tree-like optimal binning\u001b[39;00m\n\u001b[1;32m--> 722\u001b[0m         bin_list \u001b[39m=\u001b[39m woebin2_tree(\n\u001b[0;32m    723\u001b[0m           dtm, init_count_distr\u001b[39m=\u001b[39;49minit_count_distr, count_distr_limit\u001b[39m=\u001b[39;49mcount_distr_limit, \n\u001b[0;32m    724\u001b[0m           stop_limit\u001b[39m=\u001b[39;49mstop_limit, bin_num_limit\u001b[39m=\u001b[39;49mbin_num_limit, breaks\u001b[39m=\u001b[39;49mbreaks, spl_val\u001b[39m=\u001b[39;49mspl_val)\n\u001b[0;32m    725\u001b[0m     \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mchimerge\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    726\u001b[0m         \u001b[39m# 2.chimerge optimal binning\u001b[39;00m\n\u001b[0;32m    727\u001b[0m         bin_list \u001b[39m=\u001b[39m woebin2_chimerge(\n\u001b[0;32m    728\u001b[0m           dtm, init_count_distr\u001b[39m=\u001b[39minit_count_distr, count_distr_limit\u001b[39m=\u001b[39mcount_distr_limit, \n\u001b[0;32m    729\u001b[0m           stop_limit\u001b[39m=\u001b[39mstop_limit, bin_num_limit\u001b[39m=\u001b[39mbin_num_limit, breaks\u001b[39m=\u001b[39mbreaks, spl_val\u001b[39m=\u001b[39mspl_val)\n",
      "File \u001b[1;32mc:\\Users\\Shuoan\\anaconda3\\lib\\site-packages\\scorecardpy\\woebin.py:484\u001b[0m, in \u001b[0;36mwoebin2_tree\u001b[1;34m(dtm, init_count_distr, count_distr_limit, stop_limit, bin_num_limit, breaks, spl_val)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39mbinning using tree-like method\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39m    returns a dict with initial binning and special_value binning\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m# initial binning\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m bin_list \u001b[39m=\u001b[39m woebin2_init_bin(dtm, init_count_distr\u001b[39m=\u001b[39;49minit_count_distr, breaks\u001b[39m=\u001b[39;49mbreaks, spl_val\u001b[39m=\u001b[39;49mspl_val)\n\u001b[0;32m    485\u001b[0m initial_binning \u001b[39m=\u001b[39m bin_list[\u001b[39m'\u001b[39m\u001b[39minitial_binning\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    486\u001b[0m binning_sv \u001b[39m=\u001b[39m bin_list[\u001b[39m'\u001b[39m\u001b[39mbinning_sv\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Shuoan\\anaconda3\\lib\\site-packages\\scorecardpy\\woebin.py:276\u001b[0m, in \u001b[0;36mwoebin2_init_bin\u001b[1;34m(dtm, init_count_distr, breaks, spl_val)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[39minitial binning\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39m    returns a dict with initial binning and special_value binning\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m# dtm $ binning_sv\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m dtm_binsv_list \u001b[39m=\u001b[39m dtm_binning_sv(dtm, breaks, spl_val)\n\u001b[0;32m    277\u001b[0m dtm \u001b[39m=\u001b[39m dtm_binsv_list[\u001b[39m'\u001b[39m\u001b[39mdtm\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    278\u001b[0m binning_sv \u001b[39m=\u001b[39m dtm_binsv_list[\u001b[39m'\u001b[39m\u001b[39mbinning_sv\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Shuoan\\anaconda3\\lib\\site-packages\\scorecardpy\\woebin.py:115\u001b[0m, in \u001b[0;36mdtm_binning_sv\u001b[1;34m(dtm, breaks, spl_val)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sv_df[\u001b[39m'\u001b[39m\u001b[39mbin_chr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(\n\u001b[0;32m    111\u001b[0m       np\u001b[39m.\u001b[39misnan(sv_df[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]), sv_df[\u001b[39m'\u001b[39m\u001b[39mbin_chr\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m    112\u001b[0m       sv_df[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(dtm[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdtypes)\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m))\n\u001b[0;32m    113\u001b[0m     \u001b[39m# sv_df = sv_df.assign(value = lambda x: x.value.astype(dtm['value'].dtypes))\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m# dtm_sv & dtm\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m dtm_sv \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(dtm\u001b[39m.\u001b[39;49mfillna(\u001b[39m\"\u001b[39;49m\u001b[39mmissing\u001b[39;49m\u001b[39m\"\u001b[39;49m), sv_df[[\u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39;49mfillna(\u001b[39m\"\u001b[39;49m\u001b[39mmissing\u001b[39;49m\u001b[39m\"\u001b[39;49m), how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minner\u001b[39;49m\u001b[39m'\u001b[39;49m, on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m, right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    116\u001b[0m dtm \u001b[39m=\u001b[39m dtm[\u001b[39m~\u001b[39mdtm\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39misin(dtm_sv\u001b[39m.\u001b[39mindex)]\u001b[39m.\u001b[39mreset_index() \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dtm_sv\u001b[39m.\u001b[39mindex) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(dtm\u001b[39m.\u001b[39mindex) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m# dtm_sv = dtm.query('value in {}'.format(sv_df['value'].tolist()))\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m# dtm    = dtm.query('value not in {}'.format(sv_df['value'].tolist()))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Shuoan\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:106\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 106\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    107\u001b[0m         left,\n\u001b[0;32m    108\u001b[0m         right,\n\u001b[0;32m    109\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    110\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    111\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    112\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    113\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    114\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    115\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    116\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    117\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    118\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    119\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Shuoan\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:681\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[39m# stacklevel chosen to be correct when this is reached via pd.merge\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39m# (and not DataFrame.join)\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m--> 681\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_specification()\n\u001b[0;32m    683\u001b[0m cross_col \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhow \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Shuoan\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1366\u001b[0m, in \u001b[0;36m_MergeOperation._validate_specification\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1362\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mCan only pass argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mon\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m OR \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft_on\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1363\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mand \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright_on\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, not a combination of both.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1364\u001b[0m         )\n\u001b[0;32m   1365\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_index \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_index:\n\u001b[1;32m-> 1366\u001b[0m         \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1367\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mCan only pass argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mon\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m OR \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft_index\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1368\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mand \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright_index\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, not a combination of both.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1369\u001b[0m         )\n\u001b[0;32m   1370\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_on \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_on \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon\n\u001b[0;32m   1371\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_on \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mMergeError\u001b[0m: Can only pass argument \"on\" OR \"left_index\" and \"right_index\", not a combination of both."
     ]
    }
   ],
   "source": [
    "# automatically calculate bin ranges\n",
    "# bins = sc.woebin(df, y='STATUS',positive=\"bad|0\")\n",
    "bins = sc.woebin(df, y='STATUS')\n",
    "# make it easy to read the bins\n",
    "for variables , bindetails in bins.items():\n",
    "    if (variables == 'OCCUPATION_TYPE'):\n",
    "        print(bindetails)\n",
    "    print(variables , \" : \")\n",
    "    display(bindetails)\n",
    "    print(\"--\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop credit_income_ratio\n",
    "df.drop(\"credit_income_ratio\",axis=1,inplace=True)\n",
    "df.drop(\"total_enquiries_cb\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"FLAG_OWN_REALTY\",axis=1,inplace=True)\n",
    "df.drop(\"NAME_HOUSING_TYPE\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114564, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>1560726.0</td>\n",
       "      <td>41301.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3130</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>652500.0</td>\n",
       "      <td>21177.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.651862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>80865.0</td>\n",
       "      <td>5881.5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-2717</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.715042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>918468.0</td>\n",
       "      <td>28966.5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3028</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.566907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>509602.5</td>\n",
       "      <td>26149.5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1317</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.236378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0       0                   0             1          171000.0   1560726.0   \n",
       "1       0                   0             0          112500.0    652500.0   \n",
       "2       0                   0             0           67500.0     80865.0   \n",
       "3       0                   0             1          225000.0    918468.0   \n",
       "4       0                   0             0          108000.0    509602.5   \n",
       "\n",
       "   AMT_ANNUITY  NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  NAME_FAMILY_STATUS  \\\n",
       "0      41301.0                 1                    1                   1   \n",
       "1      21177.0                 5                    1                   1   \n",
       "2       5881.5                 5                    4                   1   \n",
       "3      28966.5                 5                    4                   1   \n",
       "4      26149.5                 5                    4                   1   \n",
       "\n",
       "   DAYS_EMPLOYED  OCCUPATION_TYPE  CNT_FAM_MEMBERS  EXT_SOURCE_2  \\\n",
       "0          -3130                0              3.0      0.724000   \n",
       "1           -679                3              3.0      0.651862   \n",
       "2          -2717                8              2.0      0.715042   \n",
       "3          -3028                4              3.0      0.566907   \n",
       "4          -1317                4              2.0      0.236378   \n",
       "\n",
       "   DEF_60_CNT_SOCIAL_CIRCLE   age  \n",
       "0                       0.0  37.0  \n",
       "1                       0.0  27.0  \n",
       "2                       0.0  36.0  \n",
       "3                       0.0  38.0  \n",
       "4                       0.0  35.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n"
     ]
    }
   ],
   "source": [
    "breaks_adj = {\n",
    "       'OCCUPATION_TYPE' : [1, 4, 15],\n",
    "       'NAME_INCOME_TYPE' : [0,1,5],\n",
    "        'NAME_EDUCATION_TYPE' : [0,2,3],\n",
    "        'AMT_INCOME_TOTAL' : [200000,250000, 300000,400000],\n",
    "        'DAYS_EMPLOYED' : [-5000,-3500, -2200, -1700, -1000],\n",
    "        'AMT_ANNUITY' : [4000, 7000, 16000],\n",
    "        'EXT_SOURCE_2' : [0.1,0.15,0.20,0.44,0.6,0.80],\n",
    "        'AMT_CREDIT' : [91000,150000,200000,300000],\n",
    "        'CNT_FAM_MEMBERS' : [1,2,3],\n",
    "    'NAME_FAMILY_STATUS' : [0,3],\n",
    "        'age' : [27, 30,35, 40],\n",
    "        'DEF_60_CNT_SOCIAL_CIRCLE' : [0,1,2],\n",
    "        'FLAG_OWN_CAR': [0,1]\n",
    "        \n",
    "    }\n",
    "bins_final = sc.woebin(df, y='STATUS',breaks_list=breaks_adj)\n",
    "# bins_final = sc.woebin(df, y='STATUS',breaks_list=breaks_adj, positive=\"bad|0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91651, 15)\n",
      "(22913, 15)\n"
     ]
    }
   ],
   "source": [
    "# sample code\n",
    "train, test = sc.split_df(df, 'STATUS', ratio=0.8).values()\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positive cases in train set: 0.09175022640233058\n",
      "Proportion of positive cases in test set: 0.09173831449395539\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of positive cases in train set:', train['STATUS'].mean())\n",
    "print('Proportion of positive cases in test set:', test['STATUS'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] converting into woe values ...\n",
      "[INFO] converting into woe values ...\n"
     ]
    }
   ],
   "source": [
    "# train_woe = sc.woebin_ply(train, bins_final, positive=\"bad|0\")\n",
    "# test_woe = sc.woebin_ply(test, bins_final, positive=\"bad|0\")\n",
    "train_woe = sc.woebin_ply(train, bins_final)\n",
    "test_woe = sc.woebin_ply(test, bins_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_woe.loc[:,'STATUS']\n",
    "X_train = train_woe.loc[:,train_woe.columns != 'STATUS']\n",
    "y_test = test_woe.loc[:,'STATUS']\n",
    "X_test = test_woe.loc[:,test_woe.columns != 'STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in original train set: Counter({0: 83242, 1: 8409})\n",
      "Class distribution in resampled train set: Counter({0: 8409, 1: 8409})\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution in original train set:\", Counter(y_train))\n",
    "rus = RandomUnderSampler(random_state=7)\n",
    "X_train_rus_resampled, y_train_rus_resampled = rus.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution in resampled train set:\", Counter(y_train_rus_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in original train set: Counter({0: 83242, 1: 8409})\n",
      "Class distribution in resampled train set: Counter({0: 83242, 1: 83242})\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution in original train set:\", Counter(y_train))\n",
    "ros = RandomOverSampler(random_state=7)\n",
    "X_train_ros_resampled, y_train_ros_resampled = ros.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution in resampled train set:\", Counter(y_train_ros_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in original train set: Counter({0: 83242, 1: 8409})\n",
      "Class distribution in resampled train set: Counter({0: 83242, 1: 83242})\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution in original train set:\", Counter(y_train))\n",
    "smote = SMOTE(random_state=7)\n",
    "X_train_smote_resampled, y_train_smote_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution in resampled train set:\", Counter(y_train_smote_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70762312 0.40179317 0.10333775 0.6074612  0.86220769 0.88966486\n",
      "  0.50440388 0.86035346 0.61778868 0.06325317 0.74167581 1.17754017\n",
      "  0.77701069 0.86615051]]\n",
      "[-0.00390821]\n"
     ]
    }
   ],
   "source": [
    "#create a logistic regression model object\n",
    "lr = LogisticRegression(class_weight='balanced', random_state=7)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 is good\n",
    "0 is default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6485837734037446"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = lr.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Predict Good  Predict Default\n",
      "Good            13560             7251\n",
      "Default           801             1301\n"
     ]
    }
   ],
   "source": [
    "# assume y_true and y_pred are the true and predicted labels, respectively\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "\n",
    "# create a dataframe from the confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index=['Good', 'Default'], columns=['Predict Good', 'Predict Default'])\n",
    "\n",
    "\n",
    "# print the dataframe\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positive (TP)\n",
    "The model predicts a good customer, and the client did not default <br>\n",
    "False positive (FP)\n",
    "The model predicts a good customer, but the client defaulted<br>\n",
    "True negative (TN) \n",
    "The model predicts a default, and the client defaulted<br>\n",
    "False negative (FN)\n",
    "The model predicts a default, but the client did not default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13560 7251 801 1301\n",
      "Accuracy: 0.6485837734037446\n",
      "Precision: 0.9442239398370587\n",
      "Recall: 0.6515784921435779\n",
      "Specificity: 0.6189343482397717\n",
      "F1: 0.7710678949164108\n"
     ]
    }
   ],
   "source": [
    "#import accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()\n",
    "print(tp,fn,fp,tn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) #Given that we predict positive, how often is it really positive\n",
    "recall = tp / (tp + fn) #How good at predicting positive\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp) # How good at predicting negative?\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity) \n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70589589  0.71169941 -0.01191753  0.59143766  0.91442382  0.89155576\n",
      "   0.44595473  0.85331905  0.65696645 -0.29524461  0.7783618   0.92488134\n",
      "   0.79405883  0.77128414]]\n",
      "[-0.00352012]\n"
     ]
    }
   ],
   "source": [
    "lr_rus = LogisticRegression(C=1, solver='liblinear', random_state=7)\n",
    "lr_rus.fit(X_train_rus_resampled, y_train_rus_resampled)\n",
    "print(lr_rus.coef_)\n",
    "print(lr_rus.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Predict Good  Predict Default\n",
      "Good            13560             7251\n",
      "Default           796             1306\n"
     ]
    }
   ],
   "source": [
    "y_rus_pred = lr_rus.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_rus_pred, labels=[0,1])\n",
    "df_cm = pd.DataFrame(cm, index=['Good', 'Default'], columns=['Predict Good', 'Predict Default'])\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13560 7251 796 1306\n",
      "Accuracy: 0.6488019901366037\n",
      "Precision: 0.9445528002229033\n",
      "Recall: 0.6515784921435779\n",
      "Specificity: 0.621313035204567\n",
      "F1: 0.7711775243836552\n"
     ]
    }
   ],
   "source": [
    "#import accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_rus_pred, labels=[0,1]).ravel()\n",
    "print(tp,fn,fp,tn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) #Given that we predict positive, how often is it really positive\n",
    "recall = tp / (tp + fn) #How good at predicting positive\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp) # How good at predicting negative?\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity) \n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70648937 0.48547155 0.08827639 0.6064858  0.82844671 0.89045982\n",
      "  0.5315791  0.89046923 0.63633696 0.12027072 0.7327792  1.11875963\n",
      "  0.76256482 0.90786405]]\n",
      "[-0.00543027]\n"
     ]
    }
   ],
   "source": [
    "lr_ros = LogisticRegression(C=1, solver='liblinear', random_state=7)\n",
    "lr_ros.fit(X_train_ros_resampled, y_train_ros_resampled)\n",
    "print(lr_ros.coef_)\n",
    "print(lr_ros.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Predict Good  Predict Default\n",
      "Good            13547             7264\n",
      "Default           804             1298\n"
     ]
    }
   ],
   "source": [
    "lr_ros_pred = lr_ros.predict(X_test)\n",
    "cm = confusion_matrix(y_test, lr_ros_pred, labels=[0,1])\n",
    "df_cm = pd.DataFrame(cm, index=['Good', 'Default'], columns=['Predict Good', 'Predict Default'])\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13547 7264 804 1298\n",
      "Accuracy: 0.6478854798585956\n",
      "Precision: 0.9439760295449794\n",
      "Recall: 0.6509538224977176\n",
      "Specificity: 0.6175071360608944\n",
      "F1: 0.7705477504123771\n"
     ]
    }
   ],
   "source": [
    "#import accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, lr_ros_pred, labels=[0,1]).ravel()\n",
    "print(tp,fn,fp,tn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) #Given that we predict positive, how often is it really positive\n",
    "recall = tp / (tp + fn) #How good at predicting positive\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp) # How good at predicting negative?\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity) \n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72667343  0.70091772  0.39426325  0.6422244   0.99157793  0.88773873\n",
      "   0.64308847  0.95449769  0.78345818 -1.05379915  0.61250193  1.63995605\n",
      "   0.83115168  0.63239972]]\n",
      "[-0.01549624]\n"
     ]
    }
   ],
   "source": [
    "lr_smote = LogisticRegression(C=1, solver='liblinear', random_state=7)\n",
    "lr_smote.fit(X_train_smote_resampled, y_train_smote_resampled)\n",
    "print(lr_smote.coef_)\n",
    "print(lr_smote.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Predict Good  Predict Default\n",
      "Good            13509             7302\n",
      "Default           797             1305\n"
     ]
    }
   ],
   "source": [
    "y_smote_pred = lr_smote.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_smote_pred, labels=[0,1])\n",
    "df_cm = pd.DataFrame(cm, index=['Good', 'Default'], columns=['Predict Good', 'Predict Default'])\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13509 7302 797 1305\n",
      "Accuracy: 0.6465325361148693\n",
      "Precision: 0.9442891094645604\n",
      "Recall: 0.6491278650713564\n",
      "Specificity: 0.620837297811608\n",
      "F1: 0.7693709599339351\n"
     ]
    }
   ],
   "source": [
    "#import accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_smote_pred, labels=[0,1]).ravel()\n",
    "print(tp,fn,fp,tn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) #Given that we predict positive, how often is it really positive\n",
    "recall = tp / (tp + fn) #How good at predicting positive\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp) # How good at predicting negative?\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity) \n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "def calculate(y_test,y_pred):\n",
    "    tp, fn, fp, tn = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()\n",
    "    return tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original dataset tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for i in range(1, 200):\n",
    "    numbers.append(i / 100)\n",
    "\n",
    "best_c = 1\n",
    "spec = 0.6189343482397717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    lr = LogisticRegression(random_state=7,C= i, solver= 'liblinear', class_weight='balanced')\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    res = calculate(y_test,y_pred)\n",
    "    if res > spec:\n",
    "        best_c=i\n",
    "        spec=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(best_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUS Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for i in range(1, 200):\n",
    "    numbers.append(i / 100)\n",
    "\n",
    "best_c = 1\n",
    "spec = 0.621313035204567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    lr = LogisticRegression(random_state=7,C= i, solver= 'liblinear')\n",
    "    lr.fit(X_train_rus_resampled, y_train_rus_resampled)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    res = calculate(y_test,y_pred)\n",
    "    if res > spec:\n",
    "        best_c=i\n",
    "        spec=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14\n"
     ]
    }
   ],
   "source": [
    "print(best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rus = LogisticRegression(C=1, solver='liblinear', random_state=7)\n",
    "lr_rus.fit(X_train_rus_resampled, y_train_rus_resampled)\n",
    "print(lr_rus.coef_)\n",
    "print(lr_rus.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rus_pred = lr_rus.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_rus_pred, labels=[0,1])\n",
    "df_cm = pd.DataFrame(cm, index=['Good', 'Default'], columns=['Predict Good', 'Predict Default'])\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_rus_pred, labels=[0,1]).ravel()\n",
    "print(tp,fn,fp,tn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) #Given that we predict positive, how often is it really positive\n",
    "recall = tp / (tp + fn) #How good at predicting positive\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp) # How good at predicting negative?\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity) \n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for i in range(1, 200):\n",
    "    numbers.append(i / 100)\n",
    "\n",
    "best_c = 1\n",
    "spec = 0.6175071360608944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    lr = LogisticRegression(random_state=7,C= i, solver= 'liblinear')\n",
    "    lr.fit(X_train_ros_resampled, y_train_ros_resampled)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    res = calculate(y_test,y_pred)\n",
    "    if res > spec:\n",
    "        best_c=i\n",
    "        spec=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21\n"
     ]
    }
   ],
   "source": [
    "print(best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.21, random_state=7, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.21, random_state=7, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.21, random_state=7, solver='liblinear')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=7,C= 0.21, solver= 'liblinear')\n",
    "lr.fit(X_train_ros_resampled, y_train_ros_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Predict Good  Predict Default\n",
      "Good            13547             7264\n",
      "Default           804             1298\n"
     ]
    }
   ],
   "source": [
    "lr_ros_pred = lr_ros.predict(X_test)\n",
    "cm = confusion_matrix(y_test, lr_ros_pred, labels=[0,1])\n",
    "df_cm = pd.DataFrame(cm, index=['Good', 'Default'], columns=['Predict Good', 'Predict Default'])\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13547 7264 804 1298\n",
      "Accuracy: 0.6478854798585956\n",
      "Precision: 0.9439760295449794\n",
      "Recall: 0.6509538224977176\n",
      "Specificity: 0.6175071360608944\n",
      "F1: 0.7705477504123771\n"
     ]
    }
   ],
   "source": [
    "#import accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, lr_ros_pred, labels=[0,1]).ravel()\n",
    "print(tp,fn,fp,tn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) #Given that we predict positive, how often is it really positive\n",
    "recall = tp / (tp + fn) #How good at predicting positive\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp) # How good at predicting negative?\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity) \n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for i in range(1, 200):\n",
    "    numbers.append(i / 100)\n",
    "\n",
    "best_c = 1\n",
    "spec = 0.620837297811608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    lr_smote = LogisticRegression(C=1, solver='liblinear', random_state=7)\n",
    "    lr_smote.fit(X_train_smote_resampled, y_train_smote_resampled)\n",
    "    y_pred = lr_smote.predict(X_test)\n",
    "    res = calculate(y_test,y_pred)\n",
    "    if res > spec:\n",
    "        best_c=i\n",
    "        spec=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70566543 0.49478577 0.08798268 0.60388034 0.80621461 0.89021128\n",
      "  0.52970181 0.88939432 0.63200623 0.13085229 0.73092283 1.09493738\n",
      "  0.7591641  0.90077856]]\n",
      "[-0.00541043]\n"
     ]
    }
   ],
   "source": [
    "#create a logistic regression model object\n",
    "lr_smote = LogisticRegression(C=1, solver='liblinear', random_state=7)\n",
    "lr_smote.fit(X_train_smote_resampled, y_train_smote_resampled)\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Predict Good  Predict Default\n",
      "Good            13509             7302\n",
      "Default           797             1305\n"
     ]
    }
   ],
   "source": [
    "y_smote_pred = lr_smote.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_smote_pred, labels=[0,1])\n",
    "df_cm = pd.DataFrame(cm, index=['Good', 'Default'], columns=['Predict Good', 'Predict Default'])\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13509 7302 797 1305\n",
      "Accuracy: 0.6465325361148693\n",
      "Precision: 0.9442891094645604\n",
      "Recall: 0.6491278650713564\n",
      "Specificity: 0.620837297811608\n",
      "F1: 0.7693709599339351\n"
     ]
    }
   ],
   "source": [
    "#import accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "tp, fn, fp, tn = confusion_matrix(y_test, y_smote_pred, labels=[0,1]).ravel()\n",
    "print(tp,fn,fp,tn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) #Given that we predict positive, how often is it really positive\n",
    "recall = tp / (tp + fn) #How good at predicting positive\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp) # How good at predicting negative?\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity) \n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEST SMOTE\n",
    "<br> \n",
    "Accuracy: 0.6465325361148693 <br> \n",
    "Precision: 0.9442891094645604 <br> \n",
    "Recall: 0.6491278650713564 <br> \n",
    "Specificity: 0.620837297811608 <br> \n",
    "F1: 0.7693709599339351 <br> \n",
    "\n",
    "<br>\n",
    "    \n",
    "BEST ROS\n",
    "<br> \n",
    "Accuracy: 0.6478854798585956 <br> \n",
    "Precision: 0.9439760295449794 <br> \n",
    "Recall: 0.6509538224977176<br> \n",
    "Specificity: 0.6175071360608944<br> \n",
    "F1: 0.7705477504123771<br> \n",
    "\n",
    "<br> \n",
    "    \n",
    "BEST RUS\n",
    "<br> \n",
    "Accuracy: 0.6465325361148693<br> \n",
    "Precision: 0.9442891094645604<br>\n",
    "Recall: 0.6491278650713564<br> \n",
    "Specificity: 0.620837297811608<br> \n",
    "F1: 0.7693709599339351\n",
    "\n",
    "ORIGINAL DATASET \n",
    "<br>\n",
    "Accuracy: 0.6485837734037446<br>\n",
    "Precision: 0.9442239398370587<br>\n",
    "Recall: 0.6515784921435779<br>\n",
    "Specificity: 0.6189343482397717<br>\n",
    "F1: 0.7710678949164108<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all methods had not much difference, we will still use the original dataset that is not balanced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
